## 数据收集部分

![image-20240618094651597](img/posts/链路分析实例.asserts/image-20240618094651597.png)

新建消费组构建新链路，使用原生kafka每K秒拿N条新消息打包上传到S3的形式。

对于跨天数据，目前只判断消息头尾的数据在微服务部署的时区是否归属于同一天。考虑到数据体量，暂时不考虑前端数据和Kafka生产时间不在同一天以及kafka生产顺序不一致等特殊情况。



![image-20240618171256802](img/posts/链路分析实例.asserts/image-20240618171256802.png)

## 数据分析部分

原始数据中与链路相关的内容是path，然后可以用ct和uvi标记一组数据，我们做简单的抽象就是下面这种格式。

```json
{"uvi": "user493", "el": [{"path": "/blog", "ct": "2024-05-27T11:40:36.263222"}, {"path": "/about", "ct": "2024-05-27T11:41:36.263222"}, {"path": "/services", "ct": "2024-05-27T11:44:36.263222"}, {"path": "/blog", "ct": "2024-05-27T11:52:36.263222"}, {"path": "/about", "ct": "2024-05-27T11:44:36.263222"}]}
```

我们在本地生成这种样式的数据，uvi和el中的第一个ct作为该数据的唯一标志符，然后将其访问链路进行读取，按照权重转化为下述格式。

```
source,target,weight,full_path
/contact (1),/services (2),2,/contact -> /services -> /faq -> /contact
/services (2),/faq (3),2,/contact -> /services -> /faq -> /contact
/faq (3),/contact (4),2,/contact -> /services -> /faq -> /contact
/contact (1),/faq (2),2,/contact -> /faq -> /faq
```

数据有四列，起始节点，终止节点，出现频次和在完整链路中这一小段的位置。绘制sankey图的demo只需要前三列信息。

```jso
```

![unnamed](img/posts/链路分析实例.asserts/unnamed.png)





我们参考Google Analysis提供的Sankey图，根据处理好的数据生成下述状态的示意图。

![image-20240607102045846](img/posts/链路分析实例.asserts/image-20240607102045846.png)

![image-20240607110009581](img/posts/链路分析实例.asserts/image-20240607110009581.png)

![image-20240607110140073](img/posts/链路分析实例.asserts/image-20240607110140073.png)

## 微服务部署

### 通用部署方案

在上述工作完成后，前段欧工认为问题的重心是如何从S3读取数据然后进行作业处理，最后在superset展示。

![image-20240607110201449](img/posts/链路分析实例.asserts/image-20240607110201449.png)

分为四个模块：数据源，数据处理，数据展示，操作面板。

数据处理底层使用Spark框架，可以单机部署也可以集群部署。Spark框架可接入多种数据源。

此外：在操作面板部分需要考虑权限控制，数据从数据源出来后到数据处理过程中需要考虑数据脱敏问题。



### TAUC链路分析部署

结合平台组陈建平的会议沟通内容，最后选型使用AWS EMR，可以理解为封装好的Spark分布式集群。

以节约成本考虑：本案例链路分析原始数据为AWS S3，EMR提交pyspark脚本从S3读取数据并做处理，将处理好的以供展示的数据重新写入S3，Superset使用etl工具连接数据源并展示报表。

此外，在dev和uat环境下，给EMR配置Notebook接口便于快速debug。



![image-20240607110216503](img/posts/链路分析实例.asserts/image-20240607110216503.png)



### 细节问题（TODO）

#### 1. s3的分层存储

需要了解哪些数据是用standard存放，而哪些访问的频率更低。

需要了解s3存放的数据的格式，以及原始数据是否可以直接连接到spark。



#### 2. Spark 和 S3 的连接

连接方式有多种，目前实现为Python库boto3连接。为后续性能优化考虑，使用AWS S3接口或者Spark接口，后者使用了Hadoop系统需要评估是否需要避免。



#### 3. S3 连接 Superset

目前使用的是 etl-postgre 的连接，算写中间库，需要结合成本考虑是否换掉，或者使用zero etl形式。



### 4. 大数据部资源整合问题

目前提供的思路是使用EMR账号，此外是否存在或者需要部署Python环境避免多次下载包的不轻便情况。

notebook的数据处理，分布式spark

绘制sankey图名称，

spark-数据库 连接

emr账号







## 本地配置细节

### 本地加载卷

为了防止每次重新配置都需要加载文件，可以将notebook，python环境，minio的具体文件设置在本地，然后通过配置的形式加载到docker。

### minIO

最好使用mc客户端来对文件进行存取操作，虽然连到notebook后可以通过boto3进行。

```shell
$ mc mb myminio/standard-bucket
Bucket created successfully `myminio/standard-bucket`.
$ mc cp /Users/sunhao/Desktop/pythonProject/input.txt myminio/standard-bucket/input.txt 
```



需补充Python环境和Notebook持久化部署方案

